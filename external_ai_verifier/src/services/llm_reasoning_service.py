#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ARQV30 Enhanced v3.0 - External LLM Reasoning Service
Servi√ßo de racioc√≠nio com LLMs para an√°lise aprofundada
COM ROTA√á√ÉO DE API KEYS
"""

import logging
import os
import time
import random
from typing import Dict, Any, Optional, List

# Try to import LLM clients, fallback gracefully
try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False

try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

logger = logging.getLogger(__name__)

class ExternalLLMReasoningService:
    """Servi√ßo de racioc√≠nio com LLMs externo independente com rota√ß√£o de API keys"""
    
    def __init__(self, config: Dict[str, Any]):
        """Inicializa o servi√ßo de LLM"""
        self.config = config.get('llm_reasoning', {})
        self.enabled = self.config.get('enabled', True)
        self.provider = self.config.get('provider', 'gemini').lower()
        self.model = self.config.get('model', 'gemini-2.0-flash-exp')
        self.max_tokens = self.config.get('max_tokens', 1000)
        self.temperature = self.config.get('temperature', 0.3)
        self.confidence_threshold = self.config.get('confidence_threshold', 0.6)
        
        # Par√¢metros para retry de cota
        self.max_retries_on_quota_error = self.config.get('max_retries_on_quota_error', 3)
        self.base_retry_delay = self.config.get('base_retry_delay', 1.0)
        self.max_retry_delay = self.config.get('max_retry_delay', 60.0)
        
        # ‚úÖ NOVO: Sistema de rota√ß√£o de API keys
        self.api_keys = self._load_api_keys()
        self.current_key_index = 0
        self.key_failure_count = {}  # Rastreia falhas por chave
        self.max_key_failures = 3  # M√°ximo de falhas antes de desabilitar chave
        
        self.client = None
        self._initialize_llm_client()
        
        logger.info(f"‚úÖ External LLM Reasoning Service inicializado (Provider: {self.provider}, Keys dispon√≠veis: {len(self.api_keys)}, Available: {self.client is not None})")
    
    def _load_api_keys(self) -> List[str]:
        """Carrega todas as API keys dispon√≠veis do ambiente"""
        keys = []
        
        if self.provider == 'gemini':
            # Tenta carregar GEMINI_API_KEY e GEMINI_API_KEY_1, GEMINI_API_KEY_2, etc.
            base_key = os.getenv('GEMINI_API_KEY')
            if base_key:
                keys.append(base_key)
            
            # Tenta carregar chaves numeradas
            index = 1
            while True:
                key = os.getenv(f'GEMINI_API_KEY_{index}')
                if key:
                    keys.append(key)
                    index += 1
                else:
                    break
                    
        elif self.provider == 'openai':
            base_key = os.getenv('OPENAI_API_KEY')
            if base_key:
                keys.append(base_key)
            
            index = 1
            while True:
                key = os.getenv(f'OPENAI_API_KEY_{index}')
                if key:
                    keys.append(key)
                    index += 1
                else:
                    break
        
        # Remove duplicatas mantendo a ordem
        keys = list(dict.fromkeys(keys))
        
        if keys:
            logger.info(f"üîë {len(keys)} API key(s) carregadas para {self.provider}")
        else:
            logger.warning(f"‚ö†Ô∏è Nenhuma API key encontrada para {self.provider}")
        
        return keys
    
    def _get_next_api_key(self) -> Optional[str]:
        """Obt√©m a pr√≥xima API key dispon√≠vel na rota√ß√£o"""
        if not self.api_keys:
            return None
        
        # Filtra chaves que n√£o atingiram o limite de falhas
        available_keys = [
            (i, key) for i, key in enumerate(self.api_keys)
            if self.key_failure_count.get(i, 0) < self.max_key_failures
        ]
        
        if not available_keys:
            logger.error("‚ùå Todas as API keys atingiram o limite de falhas")
            return None
        
        # Rotaciona para a pr√≥xima chave dispon√≠vel
        self.current_key_index = (self.current_key_index + 1) % len(self.api_keys)
        
        # Garante que a chave selecionada est√° dispon√≠vel
        while self.key_failure_count.get(self.current_key_index, 0) >= self.max_key_failures:
            self.current_key_index = (self.current_key_index + 1) % len(self.api_keys)
        
        selected_key = self.api_keys[self.current_key_index]
        logger.debug(f"üîÑ Usando API key #{self.current_key_index + 1} de {len(self.api_keys)}")
        
        return selected_key
    
    def _mark_key_failure(self):
        """Marca uma falha na chave atual"""
        self.key_failure_count[self.current_key_index] = \
            self.key_failure_count.get(self.current_key_index, 0) + 1
        
        failures = self.key_failure_count[self.current_key_index]
        logger.warning(f"‚ö†Ô∏è API key #{self.current_key_index + 1} falhou {failures}/{self.max_key_failures} vezes")
        
        if failures >= self.max_key_failures:
            logger.error(f"‚ùå API key #{self.current_key_index + 1} desabilitada (muitas falhas)")
    
    def _reset_key_failure(self):
        """Reseta contador de falhas da chave atual (sucesso)"""
        if self.current_key_index in self.key_failure_count:
            self.key_failure_count[self.current_key_index] = 0
    
    def _initialize_llm_client(self):
        """Inicializa o cliente LLM baseado no provider configurado"""
        try:
            if not self.api_keys:
                logger.warning(f"‚ö†Ô∏è Nenhuma API key dispon√≠vel para {self.provider}")
                return
            
            if self.provider == 'gemini' and GEMINI_AVAILABLE:
                api_key = self._get_next_api_key()
                if api_key:
                    genai.configure(api_key=api_key)
                    self.client = genai.GenerativeModel(self.model)
                    logger.info(f"‚úÖ Gemini client inicializado: {self.model} (Key #{self.current_key_index + 1})")
                    
            elif self.provider == 'openai' and OPENAI_AVAILABLE:
                api_key = self._get_next_api_key()
                if api_key:
                    openai.api_key = api_key
                    self.client = openai
                    logger.info(f"‚úÖ OpenAI client inicializado: {self.model} (Key #{self.current_key_index + 1})")
            else:
                logger.warning(f"‚ö†Ô∏è Provider '{self.provider}' n√£o dispon√≠vel ou n√£o configurado")
                
        except Exception as e:
            logger.error(f"Erro ao inicializar LLM client: {e}")
            self.client = None
    
    def _rotate_to_next_key(self) -> bool:
        """Rotaciona para a pr√≥xima chave dispon√≠vel"""
        try:
            next_key = self._get_next_api_key()
            if not next_key:
                return False
            
            if self.provider == 'gemini' and GEMINI_AVAILABLE:
                genai.configure(api_key=next_key)
                self.client = genai.GenerativeModel(self.model)
                logger.info(f"üîÑ Rotacionado para API key #{self.current_key_index + 1}")
                return True
                
            elif self.provider == 'openai' and OPENAI_AVAILABLE:
                openai.api_key = next_key
                self.client = openai
                logger.info(f"üîÑ Rotacionado para API key #{self.current_key_index + 1}")
                return True
            
            return False
            
        except Exception as e:
            logger.error(f"Erro ao rotacionar API key: {e}")
            return False
    
    def analyze_with_llm(self, text: str, context: str = "") -> Dict[str, Any]:
        """
        Analisa o texto com LLM para racioc√≠nio aprofundado
        
        Args:
            text (str): Texto para an√°lise
            context (str): Contexto adicional
            
        Returns:
            Dict[str, Any]: Resultados da an√°lise LLM
        """
        if not self.enabled or not self.client or not text or not text.strip():
            return self._get_default_result()
        
        try:
            # Prepare prompt for analysis
            prompt = self._create_analysis_prompt(text, context)
            
            # Get LLM response
            if self.provider == 'gemini':
                response = self._analyze_with_gemini_with_retry(prompt)
            elif self.provider == 'openai':
                response = self._analyze_with_openai(prompt)
            else:
                return self._get_default_result()
            
            # Parse and structure response
            analysis_result = self._parse_llm_response(response, text)
            
            # Marca sucesso da chave
            self._reset_key_failure()
            
            logger.debug(f"LLM analysis completed: confidence={analysis_result.get('llm_confidence', 0):.3f}")
            
            return analysis_result
            
        except Exception as e:
            logger.error(f"Erro na an√°lise LLM: {e}")
            return self._get_default_result()
    
    def _analyze_with_gemini_with_retry(self, prompt: str) -> str:
        """An√°lise com Gemini com l√≥gica de retry e rota√ß√£o de keys"""
        last_exception = None
        delay = self.base_retry_delay
        keys_tried = set()

        for attempt in range(self.max_retries_on_quota_error + 1):
            try:
                response = self.client.generate_content(
                    prompt,
                    generation_config=genai.types.GenerationConfig(
                        max_output_tokens=self.max_tokens,
                        temperature=self.temperature
                    )
                )
                return response.text
                
            except Exception as e:
                last_exception = e
                error_message = str(e).lower()
                
                # Verifica se √© um erro de cota
                if "429" in error_message or "quota" in error_message or "rate limit" in error_message:
                    keys_tried.add(self.current_key_index)
                    
                    # Marca falha da chave atual
                    self._mark_key_failure()
                    
                    # Tenta rotacionar para pr√≥xima chave se ainda h√° tentativas
                    if attempt < self.max_retries_on_quota_error:
                        if len(keys_tried) < len(self.api_keys):
                            logger.warning(f"Erro de cota no Gemini (tentativa {attempt + 1}), rotacionando para pr√≥xima API key...")
                            
                            if self._rotate_to_next_key():
                                # Pequeno delay antes de tentar com nova chave
                                time.sleep(1.0)
                                continue
                            else:
                                logger.error("‚ùå N√£o h√° mais API keys dispon√≠veis para rota√ß√£o")
                                break
                        else:
                            logger.warning(f"Erro de cota no Gemini (tentativa {attempt + 1}), aguardando {delay:.1f}s...")
                            time.sleep(delay)
                            delay = min(self.base_retry_delay * (2 ** attempt) + random.uniform(0, 1), self.max_retry_delay)
                    else:
                        logger.error(f"Limite de tentativas excedido para erro de cota no Gemini")
                        break
                else:
                    # Se n√£o for erro de cota, n√£o faz retry
                    logger.error(f"Erro n√£o relacionado a cota no Gemini: {e}")
                    raise

        # Se chegou aqui, todas as tentativas falharam
        if last_exception:
            raise last_exception

        raise Exception("Falha ao chamar Gemini ap√≥s tentativas de retry para cota excedida.")

    def _create_analysis_prompt(self, text: str, context: str = "") -> str:
        """Cria o prompt para an√°lise LLM"""
        base_prompt = f"""Analise o seguinte texto de forma cr√≠tica e objetiva:

TEXTO PARA AN√ÅLISE:
"{text}"

{f'CONTEXTO ADICIONAL: {context}' if context else ''}

Por favor, forne√ßa uma an√°lise estruturada considerando:

1. QUALIDADE DO CONTE√öDO (0-10):
   - Clareza e coer√™ncia
   - Fundamenta√ß√£o das afirma√ß√µes
   - Presen√ßa de evid√™ncias

2. CONFIABILIDADE (0-10):
   - Presen√ßa de fontes ou refer√™ncias
   - Linguagem objetiva vs. subjetiva
   - Sinais de credibilidade

3. VI√âS/PARCIALIDADE (0-10, onde 0=neutro, 10=muito tendencioso):
   - Linguagem emotiva ou manipulativa
   - Apresenta√ß√£o unilateral de fatos
   - Generaliza√ß√µes ou estere√≥tipos

4. RISCO DE DESINFORMA√á√ÉO (0-10):
   - Afirma√ß√µes sem evid√™ncias
   - Padr√µes t√≠picos de desinforma√ß√£o
   - Inconsist√™ncias factuais

Forne√ßa sua resposta no seguinte formato:
QUALIDADE: [pontua√ß√£o]/10 - [breve justificativa]
CONFIABILIDADE: [pontua√ß√£o]/10 - [breve justificativa]  
VI√âS: [pontua√ß√£o]/10 - [breve justificativa]
DESINFORMA√á√ÉO: [pontua√ß√£o]/10 - [breve justificativa]
RECOMENDA√á√ÉO: [APROVAR/REJEITAR/REVIS√ÉO_MANUAL] - [raz√£o principal]
CONFIAN√áA_AN√ÅLISE: [0-100]% - [justificativa da confian√ßa]"""

        return base_prompt
    
    def _analyze_with_openai(self, prompt: str) -> str:
        """An√°lise com OpenAI"""
        try:
            response = openai.ChatCompletion.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=self.max_tokens,
                temperature=self.temperature
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"Erro no OpenAI: {e}")
            raise
    
    def _parse_llm_response(self, response: str, original_text: str) -> Dict[str, Any]:
        """Parse da resposta LLM para formato estruturado"""
        try:
            import re
            
            result = {
                'llm_response': response,
                'quality_score': 5.0,
                'reliability_score': 5.0,
                'bias_score': 5.0,
                'disinformation_score': 5.0,
                'llm_recommendation': 'REVIS√ÉO_MANUAL',
                'llm_confidence': 0.5,
                'analysis_reasoning': '',
                'provider': self.provider,
                'model': self.model,
                'api_key_used': self.current_key_index + 1
            }
            
            patterns = {
                'quality_score': r'QUALIDADE:\s*([0-9]+(?:\.[0-9]+)?)',
                'reliability_score': r'CONFIABILIDADE:\s*([0-9]+(?:\.[0-9]+)?)',
                'bias_score': r'VI√âS:\s*([0-9]+(?:\.[0-9]+)?)',
                'disinformation_score': r'DESINFORMA√á√ÉO:\s*([0-9]+(?:\.[0-9]+)?)',
                'llm_recommendation': r'RECOMENDA√á√ÉO:\s*(APROVAR|REJEITAR|REVIS√ÉO_MANUAL)',
                'llm_confidence': r'CONFIAN√áA_AN√ÅLISE:\s*([0-9]+)%?'
            }
            
            for key, pattern in patterns.items():
                match = re.search(pattern, response, re.IGNORECASE)
                if match:
                    if key == 'llm_confidence':
                        result[key] = min(float(match.group(1)) / 100.0, 1.0)
                    elif key == 'llm_recommendation':
                        result[key] = match.group(1).upper()
                    else:
                        score = min(float(match.group(1)) / 10.0, 1.0)
                        result[key] = score
            
            reasoning_parts = []
            for line in response.split('\n'):
                if ' - ' in line and any(keyword in line.upper() for keyword in ['QUALIDADE', 'CONFIABILIDADE', 'VI√âS', 'DESINFORMA√á√ÉO']):
                    reasoning_parts.append(line.split(' - ', 1)[-1])
            
            result['analysis_reasoning'] = ' | '.join(reasoning_parts)
            result['llm_confidence'] = self._validate_llm_confidence(result)
            
            return result
            
        except Exception as e:
            logger.warning(f"Erro no parsing da resposta LLM: {e}")
            return {
                'llm_response': response,
                'quality_score': 0.5,
                'reliability_score': 0.5,
                'bias_score': 0.5,
                'disinformation_score': 0.5,
                'llm_recommendation': 'REVIS√ÉO_MANUAL',
                'llm_confidence': 0.3,
                'analysis_reasoning': 'Erro no parsing da resposta',
                'provider': self.provider,
                'model': self.model,
                'api_key_used': self.current_key_index + 1
            }
    
    def _validate_llm_confidence(self, result: Dict[str, Any]) -> float:
        """Valida e ajusta a confian√ßa baseada na consist√™ncia da an√°lise"""
        try:
            quality = result.get('quality_score', 0.5)
            reliability = result.get('reliability_score', 0.5) 
            bias = result.get('bias_score', 0.5)
            disinformation = result.get('disinformation_score', 0.5)
            recommendation = result.get('llm_recommendation', 'REVIS√ÉO_MANUAL')
            base_confidence = result.get('llm_confidence', 0.5)
            
            avg_positive_scores = (quality + reliability) / 2.0
            avg_negative_scores = (bias + disinformation) / 2.0
            
            expected_approval = avg_positive_scores > 0.7 and avg_negative_scores < 0.4
            expected_rejection = avg_positive_scores < 0.4 or avg_negative_scores > 0.6
            
            consistency_bonus = 0.0
            if recommendation == 'APROVAR' and expected_approval:
                consistency_bonus = 0.1
            elif recommendation == 'REJEITAR' and expected_rejection:
                consistency_bonus = 0.1
            elif recommendation == 'REVIS√ÉO_MANUAL':
                consistency_bonus = 0.05
            
            adjusted_confidence = min(base_confidence + consistency_bonus, 1.0)
            adjusted_confidence = max(adjusted_confidence, 0.1)
            
            return adjusted_confidence
            
        except Exception as e:
            logger.warning(f"Erro na valida√ß√£o de confian√ßa: {e}")
            return 0.5
    
    def _get_default_result(self) -> Dict[str, Any]:
        """Retorna resultado padr√£o quando LLM n√£o est√° dispon√≠vel"""
        return {
            'llm_response': 'LLM n√£o dispon√≠vel ou configurado',
            'quality_score': 0.5,
            'reliability_score': 0.5,
            'bias_score': 0.5,
            'disinformation_score': 0.5,
            'llm_recommendation': 'REVIS√ÉO_MANUAL',
            'llm_confidence': 0.1,
            'analysis_reasoning': 'An√°lise LLM n√£o dispon√≠vel',
            'provider': self.provider,
            'model': self.model,
            'api_key_used': 0
        }
    
    def get_keys_status(self) -> Dict[str, Any]:
        """Retorna status das API keys"""
        return {
            'total_keys': len(self.api_keys),
            'current_key_index': self.current_key_index + 1,
            'key_failures': {
                f"key_{i+1}": self.key_failure_count.get(i, 0)
                for i in range(len(self.api_keys))
            },
            'available_keys': len([
                i for i in range(len(self.api_keys))
                if self.key_failure_count.get(i, 0) < self.max_key_failures
            ])
        }